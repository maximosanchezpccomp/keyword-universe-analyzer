import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import sys
from pathlib import Path

# A√±adir el directorio ra√≠z al path
sys.path.append(str(Path(__file__).parent.parent))

from app.services.anthropic_service import AnthropicService
from app.services.semrush_service import SemrushService
from app.components.data_processor import DataProcessor
from app.components.visualizer import KeywordVisualizer
from app.utils.helpers import export_to_excel, calculate_metrics

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Keyword Universe Analyzer",
    page_icon="üåå",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personalizado
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
    }
    .metric-card {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #667eea;
    }
</style>
""", unsafe_allow_html=True)

# Inicializar session state
if 'keyword_universe' not in st.session_state:
    st.session_state.keyword_universe = None
if 'uploaded_files' not in st.session_state:
    st.session_state.uploaded_files = []
if 'processed_data' not in st.session_state:
    st.session_state.processed_data = None

def main():
    # Header
    st.markdown('<h1 class="main-header">üåå Keyword Universe Analyzer</h1>', unsafe_allow_html=True)
    st.markdown("### Crea tu universo de keywords con IA y datos competitivos")
    
    # Sidebar
    with st.sidebar:
        st.header("‚öôÔ∏è Configuraci√≥n")
        
        # Selecci√≥n de proveedor de IA
        with st.expander("ü§ñ Proveedor de IA", expanded=True):
            ai_provider = st.selectbox(
                "Selecciona el proveedor de IA",
                ["Claude (Anthropic)", "OpenAI", "Ambos (Validaci√≥n Cruzada)"],
                help="Claude Sonnet 4.5 es m√°s anal√≠tico. GPT-4 es m√°s r√°pido."
            )
        
        # API Keys
        with st.expander("üîë API Keys", expanded=True):
            anthropic_key = None
            openai_key = None
            
            if ai_provider in ["Claude (Anthropic)", "Ambos (Validaci√≥n Cruzada)"]:
                anthropic_key = st.text_input("Anthropic API Key", type="password", 
                                             help="Tu API key de Claude")
            
            if ai_provider in ["OpenAI", "Ambos (Validaci√≥n Cruzada)"]:
                openai_key = st.text_input("OpenAI API Key", type="password",
                                          help="Tu API key de OpenAI")
            
            semrush_key = st.text_input("Semrush API Key", type="password",
                                       help="Tu API key de Semrush (opcional)")
        
        # Configuraci√≥n del an√°lisis
        with st.expander("üéØ Par√°metros de An√°lisis"):
            max_keywords = st.slider("M√°ximo de keywords por competidor", 
                                    100, 5000, 1000, 100)
            min_volume = st.number_input("Volumen m√≠nimo de b√∫squeda", 
                                        min_value=0, value=10)
            
            # Selecci√≥n de modelo seg√∫n proveedor
            if ai_provider == "Claude (Anthropic)":
                model_choice = st.selectbox("Modelo Claude", 
                                           ["claude-sonnet-4-5-20250929", 
                                            "claude-opus-4-20250514"])
            elif ai_provider == "OpenAI":
                model_choice = st.selectbox("Modelo OpenAI",
                                           ["gpt-4o",
                                            "gpt-4-turbo",
                                            "gpt-4",
                                            "gpt-3.5-turbo"])
            else:  # Ambos
                col1, col2 = st.columns(2)
                with col1:
                    claude_model = st.selectbox("Modelo Claude", 
                                               ["claude-sonnet-4-5-20250929", 
                                                "claude-opus-4-20250514"])
                with col2:
                    openai_model = st.selectbox("Modelo OpenAI",
                                               ["gpt-4o",
                                                "gpt-4-turbo"])
        
        st.divider()
        
        # Info
        st.info("üí° **Tip:** Sube archivos CSV o Excel de Ahrefs, Semrush o similar con columnas: keyword, volume, traffic")
    
    # Tabs principales
    tab1, tab2, tab3, tab4 = st.tabs([
        "üìÅ Carga de Datos", 
        "üß† An√°lisis con IA", 
        "üìä Visualizaci√≥n",
        "üì• Exportar"
    ])
    
    # TAB 1: Carga de datos
    with tab1:
        st.header("Carga tus archivos de keywords")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # Opci√≥n 1: Cargar archivos
            st.subheader("Opci√≥n 1: Cargar archivos exportados")
            uploaded_files = st.file_uploader(
                "Sube archivos CSV o Excel de tus competidores",
                type=['csv', 'xlsx', 'xls'],
                accept_multiple_files=True,
                help="Archivos exportados de Ahrefs, Semrush, etc."
            )
            
            if uploaded_files:
                st.session_state.uploaded_files = uploaded_files
                st.success(f"‚úÖ {len(uploaded_files)} archivo(s) cargado(s)")
                
                # Preview de los datos
                for file in uploaded_files:
                    with st.expander(f"üëÅÔ∏è Preview: {file.name}"):
                        try:
                            if file.name.endswith('.csv'):
                                df = pd.read_csv(file)
                            else:
                                df = pd.read_excel(file)
                            
                            st.dataframe(df.head(10), use_container_width=True)
                            st.caption(f"Total rows: {len(df)} | Columns: {', '.join(df.columns)}")
                        except Exception as e:
                            st.error(f"Error al leer el archivo: {str(e)}")
        
        with col2:
            # Opci√≥n 2: Integraci√≥n directa con Semrush
            st.subheader("Opci√≥n 2: Semrush API")
            
            if semrush_key:
                competitor_domains = st.text_area(
                    "Dominios competidores (uno por l√≠nea)",
                    placeholder="example.com\ncompetitor.com",
                    height=150
                )
                
                if st.button("üîç Obtener Keywords", type="primary"):
                    if competitor_domains:
                        domains = [d.strip() for d in competitor_domains.split('\n') if d.strip()]
                        
                        with st.spinner("Obteniendo datos de Semrush..."):
                            semrush = SemrushService(semrush_key)
                            all_data = []
                            
                            progress_bar = st.progress(0)
                            for i, domain in enumerate(domains):
                                try:
                                    data = semrush.get_organic_keywords(domain, limit=max_keywords)
                                    all_data.append(data)
                                    st.success(f"‚úÖ {domain}: {len(data)} keywords")
                                except Exception as e:
                                    st.error(f"‚ùå Error con {domain}: {str(e)}")
                                
                                progress_bar.progress((i + 1) / len(domains))
                            
                            if all_data:
                                st.session_state.processed_data = pd.concat(all_data, ignore_index=True)
                                st.success(f"üéâ Total: {len(st.session_state.processed_data)} keywords obtenidas")
            else:
                st.warning("‚ö†Ô∏è Ingresa tu API key de Semrush")
    
    # TAB 2: An√°lisis con IA
    with tab2:
        st.header("An√°lisis con IA")
        
        # Validar API keys seg√∫n proveedor
        if ai_provider == "Claude (Anthropic)" and not anthropic_key:
            st.warning("‚ö†Ô∏è Por favor ingresa tu API key de Anthropic en la barra lateral")
            return
        elif ai_provider == "OpenAI" and not openai_key:
            st.warning("‚ö†Ô∏è Por favor ingresa tu API key de OpenAI en la barra lateral")
            return
        elif ai_provider == "Ambos (Validaci√≥n Cruzada)" and (not anthropic_key or not openai_key):
            st.warning("‚ö†Ô∏è Para validaci√≥n cruzada necesitas ambas API keys")
            return
        
        if not st.session_state.uploaded_files and st.session_state.processed_data is None:
            st.info("üìÅ Primero carga datos en la pesta√±a 'Carga de Datos'")
            return
        
        # Preparar datos
        if st.session_state.processed_data is None and st.session_state.uploaded_files:
            processor = DataProcessor()
            st.session_state.processed_data = processor.process_files(
                st.session_state.uploaded_files, 
                max_keywords
            )
        
        if st.session_state.processed_data is not None:
            df = st.session_state.processed_data
            
            # M√©tricas r√°pidas
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Total Keywords", f"{len(df):,}")
            with col2:
                st.metric("Volumen Total", f"{df['volume'].sum():,.0f}")
            with col3:
                st.metric("Keywords √önicas", f"{df['keyword'].nunique():,}")
            with col4:
                st.metric("Volumen Promedio", f"{df['volume'].mean():,.0f}")
            
            st.divider()
            
            # Configuraci√≥n del prompt
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.subheader("Configuraci√≥n del an√°lisis")
                
                analysis_type = st.radio(
                    "Tipo de agrupaci√≥n",
                    ["Tem√°tica (Topics)", "Intenci√≥n de b√∫squeda", "Funnel de conversi√≥n"],
                    horizontal=True
                )
                
                num_tiers = st.slider("N√∫mero de niveles (tiers)", 2, 5, 3)
                
                custom_instructions = st.text_area(
                    "Instrucciones adicionales (opcional)",
                    placeholder="Ej: Enf√≥cate en keywords transaccionales, agrupa por producto, etc.",
                    height=100
                )
            
            with col2:
                st.subheader("Opciones avanzadas")
                include_semantic = st.checkbox("An√°lisis sem√°ntico profundo", value=True)
                include_trends = st.checkbox("Identificar tendencias emergentes", value=True)
                include_gaps = st.checkbox("Detectar gaps de contenido", value=True)
            
            # Bot√≥n de an√°lisis
            if st.button("üöÄ Analizar con IA", type="primary", use_container_width=True):
                with st.spinner(f"üß† {ai_provider.split('(')[0].strip()} est√° analizando tu universo de keywords..."):
                    try:
                        if ai_provider == "Claude (Anthropic)":
                            # An√°lisis con Claude
                            anthropic_service = AnthropicService(anthropic_key, model_choice)
                            
                            prompt = anthropic_service.create_universe_prompt(
                                df,
                                analysis_type=analysis_type,
                                num_tiers=num_tiers,
                                custom_instructions=custom_instructions,
                                include_semantic=include_semantic,
                                include_trends=include_trends,
                                include_gaps=include_gaps
                            )
                            
                            result = anthropic_service.analyze_keywords(prompt, df)
                            result['provider'] = 'Claude'
                            result['model'] = model_choice
                            
                        elif ai_provider == "OpenAI":
                            # An√°lisis con OpenAI
                            from app.services.openai_service import OpenAIService
                            
                            openai_service = OpenAIService(openai_key, model_choice)
                            
                            messages = openai_service.create_universe_prompt(
                                df,
                                analysis_type=analysis_type,
                                num_tiers=num_tiers,
                                custom_instructions=custom_instructions,
                                include_semantic=include_semantic,
                                include_trends=include_trends,
                                include_gaps=include_gaps
                            )
                            
                            result = openai_service.analyze_keywords(messages, df)
                            result['provider'] = 'OpenAI'
                            result['model'] = model_choice
                            
                        else:  # Ambos (Validaci√≥n Cruzada)
                            from app.services.openai_service import OpenAIService
                            
                            # An√°lisis con Claude
                            st.info("1Ô∏è‚É£ Analizando con Claude...")
                            anthropic_service = AnthropicService(anthropic_key, claude_model)
                            
                            prompt_claude = anthropic_service.create_universe_prompt(
                                df,
                                analysis_type=analysis_type,
                                num_tiers=num_tiers,
                                custom_instructions=custom_instructions,
                                include_semantic=include_semantic,
                                include_trends=include_trends,
                                include_gaps=include_gaps
                            )
                            
                            result_claude = anthropic_service.analyze_keywords(prompt_claude, df)
                            
                            # An√°lisis con OpenAI
                            st.info("2Ô∏è‚É£ Analizando con OpenAI...")
                            openai_service = OpenAIService(openai_key, openai_model)
                            
                            messages_openai = openai_service.create_universe_prompt(
                                df,
                                analysis_type=analysis_type,
                                num_tiers=num_tiers,
                                custom_instructions=custom_instructions,
                                include_semantic=include_semantic,
                                include_trends=include_trends,
                                include_gaps=include_gaps
                            )
                            
                            result_openai = openai_service.analyze_keywords(messages_openai, df)
                            
                            # Validaci√≥n cruzada
                            st.info("3Ô∏è‚É£ Comparando resultados...")
                            comparison = openai_service.compare_with_claude(result_claude, df)
                            
                            # Combinar resultados
                            result = {
                                'summary': f"**An√°lisis de Claude:**\n{result_claude.get('summary', '')}\n\n**An√°lisis de OpenAI:**\n{result_openai.get('summary', '')}",
                                'topics': result_claude.get('topics', []),
                                'topics_openai': result_openai.get('topics', []),
                                'comparison': comparison,
                                'provider': 'Ambos',
                                'models': f"Claude: {claude_model} | OpenAI: {openai_model}"
                            }
                            
                            if 'gaps' in result_claude:
                                result['gaps'] = result_claude['gaps']
                            if 'trends' in result_claude:
                                result['trends'] = result_claude['trends']
                        
                        st.session_state.keyword_universe = result
                        
                        st.success("‚úÖ ¬°An√°lisis completado!")
                        st.balloons()
                        
                    except Exception as e:
                        st.error(f"‚ùå Error en el an√°lisis: {str(e)}")
                        import traceback
                        with st.expander("Ver detalles del error"):
                            st.code(traceback.format_exc())
            
            # Mostrar resultados si existen
            if st.session_state.keyword_universe:
                st.divider()
                st.subheader("üìã Resultados del An√°lisis")
                
                result = st.session_state.keyword_universe
                
                # Mostrar info del proveedor
                provider_col1, provider_col2 = st.columns(2)
                with provider_col1:
                    st.metric("Proveedor de IA", result.get('provider', 'N/A'))
                with provider_col2:
                    if result.get('provider') == 'Ambos':
                        st.metric("Modelos", result.get('models', 'N/A'))
                    else:
                        st.metric("Modelo", result.get('model', 'N/A'))
                
                # Resumen ejecutivo
                with st.expander("üìä Resumen Ejecutivo", expanded=True):
                    st.markdown(result.get('summary', 'No disponible'))
                
                # Si es validaci√≥n cruzada, mostrar comparaci√≥n
                if result.get('provider') == 'Ambos' and 'comparison' in result:
                    with st.expander("üîÑ Validaci√≥n Cruzada", expanded=True):
                        comp = result['comparison']
                        st.markdown("**Validaci√≥n General:**")
                        st.info(comp.get('validation', 'N/A'))
                        
                        if 'missing_topics' in comp and comp['missing_topics']:
                            st.markdown("**Topics Adicionales Sugeridos por OpenAI:**")
                            for topic in comp['missing_topics']:
                                st.markdown(f"- {topic}")
                        
                        if 'improvements' in comp and comp['improvements']:
                            st.markdown("**Mejoras Sugeridas:**")
                            for improvement in comp['improvements']:
                                st.markdown(f"- {improvement}")
                
                # Topics por tier
                if 'topics' in result:
                    st.subheader("üéØ Topics Identificados (Claude)" if result.get('provider') == 'Ambos' else "üéØ Topics Identificados")
                    
                    topics_df = pd.DataFrame(result['topics'])
                    
                    # Filtros
                    col1, col2 = st.columns(2)
                    with col1:
                        tier_filter = st.multiselect(
                            "Filtrar por Tier",
                            options=topics_df['tier'].unique(),
                            default=topics_df['tier'].unique()
                        )
                    with col2:
                        sort_by = st.selectbox("Ordenar por", 
                                              ["volume", "keyword_count", "priority"])
                    
                    filtered_topics = topics_df[topics_df['tier'].isin(tier_filter)].sort_values(
                        by=sort_by, ascending=False
                    )
                    
                    st.dataframe(filtered_topics, use_container_width=True, height=400)
                
                # Si hay an√°lisis de OpenAI tambi√©n, mostrarlo
                if result.get('provider') == 'Ambos' and 'topics_openai' in result:
                    st.subheader("üéØ Topics Identificados (OpenAI)")
                    topics_openai_df = pd.DataFrame(result['topics_openai'])
                    st.dataframe(topics_openai_df, use_container_width=True, height=400)
    
    # TAB 3: Visualizaci√≥n
    with tab3:
        st.header("Visualizaci√≥n del Keyword Universe")
        
        if st.session_state.keyword_universe is None:
            st.info("üß† Primero realiza el an√°lisis con Claude en la pesta√±a anterior")
            return
        
        result = st.session_state.keyword_universe
        
        if 'topics' in result:
            visualizer = KeywordVisualizer()
            topics_df = pd.DataFrame(result['topics'])
            
            # Gr√°fico de burbujas
            st.subheader("ü´ß Mapa de Topics (Bubble Chart)")
            
            fig_bubble = visualizer.create_bubble_chart(topics_df)
            st.plotly_chart(fig_bubble, use_container_width=True)
            
            col1, col2 = st.columns(2)
            
            with col1:
                # Treemap
                st.subheader("üó∫Ô∏è Treemap por Volumen")
                fig_treemap = visualizer.create_treemap(topics_df)
                st.plotly_chart(fig_treemap, use_container_width=True)
            
            with col2:
                # Sunburst
                st.subheader("‚òÄÔ∏è Distribuci√≥n por Tier")
                fig_sunburst = visualizer.create_sunburst(topics_df)
                st.plotly_chart(fig_sunburst, use_container_width=True)
            
            # An√°lisis de gaps
            if 'gaps' in result:
                st.divider()
                st.subheader("üéØ Oportunidades de Contenido")
                
                for i, gap in enumerate(result['gaps'][:5]):
                    with st.expander(f"üí° Oportunidad {i+1}: {gap.get('topic', 'N/A')}"):
                        st.markdown(gap.get('description', 'N/A'))
                        st.metric("Volumen potencial", f"{gap.get('volume', 0):,.0f}")
    
    # TAB 4: Exportar
    with tab4:
        st.header("Exportar Resultados")
        
        if st.session_state.keyword_universe is None:
            st.info("üß† Primero realiza el an√°lisis con Claude")
            return
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("üìÑ Formato de exportaci√≥n")
            
            export_format = st.radio(
                "Selecciona el formato",
                ["Excel (.xlsx)", "CSV", "JSON"],
                horizontal=True
            )
            
            include_visuals = st.checkbox("Incluir gr√°ficos (solo Excel)", value=True)
            
            if st.button("üíæ Generar archivo", type="primary"):
                with st.spinner("Generando archivo..."):
                    try:
                        if export_format == "Excel (.xlsx)":
                            file_data = export_to_excel(
                                st.session_state.keyword_universe,
                                include_visuals
                            )
                            st.download_button(
                                "‚¨áÔ∏è Descargar Excel",
                                data=file_data,
                                file_name=f"keyword_universe_{datetime.now().strftime('%Y%m%d')}.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                            )
                        elif export_format == "CSV":
                            topics_df = pd.DataFrame(st.session_state.keyword_universe['topics'])
                            csv_data = topics_df.to_csv(index=False)
                            st.download_button(
                                "‚¨áÔ∏è Descargar CSV",
                                data=csv_data,
                                file_name=f"keyword_universe_{datetime.now().strftime('%Y%m%d')}.csv",
                                mime="text/csv"
                            )
                        else:  # JSON
                            import json
                            json_data = json.dumps(st.session_state.keyword_universe, indent=2)
                            st.download_button(
                                "‚¨áÔ∏è Descargar JSON",
                                data=json_data,
                                file_name=f"keyword_universe_{datetime.now().strftime('%Y%m%d')}.json",
                                mime="application/json"
                            )
                        
                        st.success("‚úÖ Archivo generado correctamente")
                    except Exception as e:
                        st.error(f"‚ùå Error al generar archivo: {str(e)}")
        
        with col2:
            st.subheader("üìä Resumen de datos")
            
            result = st.session_state.keyword_universe
            
            if 'topics' in result:
                topics_df = pd.DataFrame(result['topics'])
                
                st.metric("Total Topics", len(topics_df))
                st.metric("Keywords Analizadas", topics_df['keyword_count'].sum())
                st.metric("Volumen Total", f"{topics_df['volume'].sum():,.0f}")
                
                st.divider()
                
                st.caption("Distribuci√≥n por Tier:")
                tier_dist = topics_df.groupby('tier').size()
                for tier, count in tier_dist.items():
                    st.text(f"Tier {tier}: {count} topics")

if __name__ == "__main__":
    main()
