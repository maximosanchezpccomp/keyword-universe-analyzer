import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import sys
from pathlib import Path

# A√±adir el directorio ra√≠z al path
sys.path.append(str(Path(__file__).parent.parent))

from app.services.anthropic_service import AnthropicService
from app.services.semrush_service import SemrushService
from app.components.data_processor import DataProcessor
from app.components.visualizer import KeywordVisualizer
from app.utils.helpers import export_to_excel, calculate_metrics

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Keyword Universe Analyzer",
    page_icon="üåå",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personalizado
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
    }
    .metric-card {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #667eea;
    }
</style>
""", unsafe_allow_html=True)

# Inicializar session state
if 'keyword_universe' not in st.session_state:
    st.session_state.keyword_universe = None
if 'uploaded_files' not in st.session_state:
    st.session_state.uploaded_files = []
if 'processed_data' not in st.session_state:
    st.session_state.processed_data = None

def main():
    # Header
    st.markdown('<h1 class="main-header">üåå Keyword Universe Analyzer</h1>', unsafe_allow_html=True)
    st.markdown("### Crea tu universo de keywords con IA y datos competitivos")
    
    # Sidebar
    with st.sidebar:
        st.header("‚öôÔ∏è Configuraci√≥n")
        
        # API Keys
        with st.expander("üîë API Keys", expanded=True):
            anthropic_key = st.text_input("Anthropic API Key", type="password", 
                                         help="Tu API key de Claude")
            semrush_key = st.text_input("Semrush API Key", type="password",
                                       help="Tu API key de Semrush (opcional)")
        
        # Configuraci√≥n del an√°lisis
        with st.expander("üéØ Par√°metros de An√°lisis"):
            max_keywords = st.slider("M√°ximo de keywords por competidor", 
                                    100, 5000, 1000, 100)
            min_volume = st.number_input("Volumen m√≠nimo de b√∫squeda", 
                                        min_value=0, value=10)
            model_choice = st.selectbox("Modelo Claude", 
                                       ["claude-sonnet-4-5-20250929", 
                                        "claude-opus-4-20250514"])
        
        st.divider()
        
        # Info
        st.info("üí° **Tip:** Sube archivos CSV o Excel de Ahrefs, Semrush o similar con columnas: keyword, volume, traffic")
    
    # Tabs principales
    tab1, tab2, tab3, tab4 = st.tabs([
        "üìÅ Carga de Datos", 
        "üß† An√°lisis con IA", 
        "üìä Visualizaci√≥n",
        "üì• Exportar"
    ])
    
    # TAB 1: Carga de datos
    with tab1:
        st.header("Carga tus archivos de keywords")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # Opci√≥n 1: Cargar archivos
            st.subheader("Opci√≥n 1: Cargar archivos exportados")
            uploaded_files = st.file_uploader(
                "Sube archivos CSV o Excel de tus competidores",
                type=['csv', 'xlsx', 'xls'],
                accept_multiple_files=True,
                help="Archivos exportados de Ahrefs, Semrush, etc."
            )
            
            if uploaded_files:
                st.session_state.uploaded_files = uploaded_files
                st.success(f"‚úÖ {len(uploaded_files)} archivo(s) cargado(s)")
                
                # Preview de los datos
                for file in uploaded_files:
                    with st.expander(f"üëÅÔ∏è Preview: {file.name}"):
                        try:
                            if file.name.endswith('.csv'):
                                df = pd.read_csv(file)
                            else:
                                df = pd.read_excel(file)
                            
                            st.dataframe(df.head(10), use_container_width=True)
                            st.caption(f"Total rows: {len(df)} | Columns: {', '.join(df.columns)}")
                        except Exception as e:
                            st.error(f"Error al leer el archivo: {str(e)}")
        
        with col2:
            # Opci√≥n 2: Integraci√≥n directa con Semrush
            st.subheader("Opci√≥n 2: Semrush API")
            
            if semrush_key:
                competitor_domains = st.text_area(
                    "Dominios competidores (uno por l√≠nea)",
                    placeholder="example.com\ncompetitor.com",
                    height=150
                )
                
                if st.button("üîç Obtener Keywords", type="primary"):
                    if competitor_domains:
                        domains = [d.strip() for d in competitor_domains.split('\n') if d.strip()]
                        
                        with st.spinner("Obteniendo datos de Semrush..."):
                            semrush = SemrushService(semrush_key)
                            all_data = []
                            
                            progress_bar = st.progress(0)
                            for i, domain in enumerate(domains):
                                try:
                                    data = semrush.get_organic_keywords(domain, limit=max_keywords)
                                    all_data.append(data)
                                    st.success(f"‚úÖ {domain}: {len(data)} keywords")
                                except Exception as e:
                                    st.error(f"‚ùå Error con {domain}: {str(e)}")
                                
                                progress_bar.progress((i + 1) / len(domains))
                            
                            if all_data:
                                st.session_state.processed_data = pd.concat(all_data, ignore_index=True)
                                st.success(f"üéâ Total: {len(st.session_state.processed_data)} keywords obtenidas")
            else:
                st.warning("‚ö†Ô∏è Ingresa tu API key de Semrush")
    
    # TAB 2: An√°lisis con IA
    with tab2:
        st.header("An√°lisis con Claude")
        
        if not anthropic_key:
            st.warning("‚ö†Ô∏è Por favor ingresa tu API key de Anthropic en la barra lateral")
            return
        
        if not st.session_state.uploaded_files and st.session_state.processed_data is None:
            st.info("üìÅ Primero carga datos en la pesta√±a 'Carga de Datos'")
            return
        
        # Preparar datos
        if st.session_state.processed_data is None and st.session_state.uploaded_files:
            processor = DataProcessor()
            st.session_state.processed_data = processor.process_files(
                st.session_state.uploaded_files, 
                max_keywords
            )
        
        if st.session_state.processed_data is not None:
            df = st.session_state.processed_data
            
            # M√©tricas r√°pidas
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Total Keywords", f"{len(df):,}")
            with col2:
                st.metric("Volumen Total", f"{df['volume'].sum():,.0f}")
            with col3:
                st.metric("Keywords √önicas", f"{df['keyword'].nunique():,}")
            with col4:
                st.metric("Volumen Promedio", f"{df['volume'].mean():,.0f}")
            
            st.divider()
            
            # Configuraci√≥n del prompt
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.subheader("Configuraci√≥n del an√°lisis")
                
                analysis_type = st.radio(
                    "Tipo de agrupaci√≥n",
                    ["Tem√°tica (Topics)", "Intenci√≥n de b√∫squeda", "Funnel de conversi√≥n"],
                    horizontal=True
                )
                
                num_tiers = st.slider("N√∫mero de niveles (tiers)", 2, 5, 3)
                
                custom_instructions = st.text_area(
                    "Instrucciones adicionales (opcional)",
                    placeholder="Ej: Enf√≥cate en keywords transaccionales, agrupa por producto, etc.",
                    height=100
                )
            
            with col2:
                st.subheader("Opciones avanzadas")
                include_semantic = st.checkbox("An√°lisis sem√°ntico profundo", value=True)
                include_trends = st.checkbox("Identificar tendencias emergentes", value=True)
                include_gaps = st.checkbox("Detectar gaps de contenido", value=True)
            
            # Bot√≥n de an√°lisis
            if st.button("üöÄ Analizar con Claude", type="primary", use_container_width=True):
                with st.spinner("üß† Claude est√° analizando tu universo de keywords..."):
                    try:
                        anthropic_service = AnthropicService(anthropic_key, model_choice)
                        
                        # Crear el prompt
                        prompt = anthropic_service.create_universe_prompt(
                            df,
                            analysis_type=analysis_type,
                            num_tiers=num_tiers,
                            custom_instructions=custom_instructions,
                            include_semantic=include_semantic,
                            include_trends=include_trends,
                            include_gaps=include_gaps
                        )
                        
                        # Llamar a Claude
                        result = anthropic_service.analyze_keywords(prompt, df)
                        
                        st.session_state.keyword_universe = result
                        
                        st.success("‚úÖ ¬°An√°lisis completado!")
                        st.balloons()
                        
                    except Exception as e:
                        st.error(f"‚ùå Error en el an√°lisis: {str(e)}")
            
            # Mostrar resultados si existen
            if st.session_state.keyword_universe:
                st.divider()
                st.subheader("üìã Resultados del An√°lisis")
                
                result = st.session_state.keyword_universe
                
                # Resumen ejecutivo
                with st.expander("üìä Resumen Ejecutivo", expanded=True):
                    st.markdown(result.get('summary', 'No disponible'))
                
                # Topics por tier
                if 'topics' in result:
                    st.subheader("üéØ Topics Identificados")
                    
                    topics_df = pd.DataFrame(result['topics'])
                    
                    # Filtros
                    col1, col2 = st.columns(2)
                    with col1:
                        tier_filter = st.multiselect(
                            "Filtrar por Tier",
                            options=topics_df['tier'].unique(),
                            default=topics_df['tier'].unique()
                        )
                    with col2:
                        sort_by = st.selectbox("Ordenar por", 
                                              ["volume", "keyword_count", "priority"])
                    
                    filtered_topics = topics_df[topics_df['tier'].isin(tier_filter)].sort_values(
                        by=sort_by, ascending=False
                    )
                    
                    st.dataframe(filtered_topics, use_container_width=True, height=400)
    
    # TAB 3: Visualizaci√≥n
    with tab3:
        st.header("Visualizaci√≥n del Keyword Universe")
        
        if st.session_state.keyword_universe is None:
            st.info("üß† Primero realiza el an√°lisis con Claude en la pesta√±a anterior")
            return
        
        result = st.session_state.keyword_universe
        
        if 'topics' in result:
            visualizer = KeywordVisualizer()
            topics_df = pd.DataFrame(result['topics'])
            
            # Gr√°fico de burbujas
            st.subheader("ü´ß Mapa de Topics (Bubble Chart)")
            
            fig_bubble = visualizer.create_bubble_chart(topics_df)
            st.plotly_chart(fig_bubble, use_container_width=True)
            
            col1, col2 = st.columns(2)
            
            with col1:
                # Treemap
                st.subheader("üó∫Ô∏è Treemap por Volumen")
                fig_treemap = visualizer.create_treemap(topics_df)
                st.plotly_chart(fig_treemap, use_container_width=True)
            
            with col2:
                # Sunburst
                st.subheader("‚òÄÔ∏è Distribuci√≥n por Tier")
                fig_sunburst = visualizer.create_sunburst(topics_df)
                st.plotly_chart(fig_sunburst, use_container_width=True)
            
            # An√°lisis de gaps
            if 'gaps' in result:
                st.divider()
                st.subheader("üéØ Oportunidades de Contenido")
                
                for i, gap in enumerate(result['gaps'][:5]):
                    with st.expander(f"üí° Oportunidad {i+1}: {gap.get('topic', 'N/A')}"):
                        st.markdown(gap.get('description', 'N/A'))
                        st.metric("Volumen potencial", f"{gap.get('volume', 0):,.0f}")
    
    # TAB 4: Exportar
    with tab4:
        st.header("Exportar Resultados")
        
        if st.session_state.keyword_universe is None:
            st.info("üß† Primero realiza el an√°lisis con Claude")
            return
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("üìÑ Formato de exportaci√≥n")
            
            export_format = st.radio(
                "Selecciona el formato",
                ["Excel (.xlsx)", "CSV", "JSON"],
                horizontal=True
            )
            
            include_visuals = st.checkbox("Incluir gr√°ficos (solo Excel)", value=True)
            
            if st.button("üíæ Generar archivo", type="primary"):
                with st.spinner("Generando archivo..."):
                    try:
                        if export_format == "Excel (.xlsx)":
                            file_data = export_to_excel(
                                st.session_state.keyword_universe,
                                include_visuals
                            )
                            st.download_button(
                                "‚¨áÔ∏è Descargar Excel",
                                data=file_data,
                                file_name=f"keyword_universe_{datetime.now().strftime('%Y%m%d')}.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                            )
                        elif export_format == "CSV":
                            topics_df = pd.DataFrame(st.session_state.keyword_universe['topics'])
                            csv_data = topics_df.to_csv(index=False)
                            st.download_button(
                                "‚¨áÔ∏è Descargar CSV",
                                data=csv_data,
                                file_name=f"keyword_universe_{datetime.now().strftime('%Y%m%d')}.csv",
                                mime="text/csv"
                            )
                        else:  # JSON
                            import json
                            json_data = json.dumps(st.session_state.keyword_universe, indent=2)
                            st.download_button(
                                "‚¨áÔ∏è Descargar JSON",
                                data=json_data,
                                file_name=f"keyword_universe_{datetime.now().strftime('%Y%m%d')}.json",
                                mime="application/json"
                            )
                        
                        st.success("‚úÖ Archivo generado correctamente")
                    except Exception as e:
                        st.error(f"‚ùå Error al generar archivo: {str(e)}")
        
        with col2:
            st.subheader("üìä Resumen de datos")
            
            result = st.session_state.keyword_universe
            
            if 'topics' in result:
                topics_df = pd.DataFrame(result['topics'])
                
                st.metric("Total Topics", len(topics_df))
                st.metric("Keywords Analizadas", topics_df['keyword_count'].sum())
                st.metric("Volumen Total", f"{topics_df['volume'].sum():,.0f}")
                
                st.divider()
                
                st.caption("Distribuci√≥n por Tier:")
                tier_dist = topics_df.groupby('tier').size()
                for tier, count in tier_dist.items():
                    st.text(f"Tier {tier}: {count} topics")

if __name__ == "__main__":
    main()
